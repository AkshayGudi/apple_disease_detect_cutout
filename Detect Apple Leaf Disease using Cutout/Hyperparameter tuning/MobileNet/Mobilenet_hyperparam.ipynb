{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "apple_mobilenet_hyperparam.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "088RAVSFHFjA"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjf1zF--Dx5O"
      },
      "source": [
        "#<h1><center><b> Apple Disease MobileNet Hyperparameter </b></center></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "088RAVSFHFjA"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-TrJ0lVpsHS"
      },
      "source": [
        "# from google.colab import files\n",
        "\n",
        "import os, sys, pdb, shutil, time, random\n",
        "import argparse\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as func\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from shutil import copyfile\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torchvision.utils import make_grid\n",
        "from skimage import io\n",
        "# import splitfolders as sp\n",
        "from torch.optim import Adam\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdIbQoi7NDND",
        "outputId": "cc3a3243-4310-41d0-8714-ab27af900752"
      },
      "source": [
        "!pip install bayesian-optimization"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11687 sha256=f1feb2220bf5ee3141a1c77db047c60d363255de603e56a9af97ced402c8fb17\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IduO2rOyMera"
      },
      "source": [
        "## 1.Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvp65q6dFetJ"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2iDom-tFeqH"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PxpFw4UFeGO",
        "outputId": "b5febe26-4b2a-425f-8355-9d10c0b75954"
      },
      "source": [
        "!kaggle datasets download -d akshaygudi/apple-leaf-disease"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading plantpathology-apple-dataset.zip to /content\n",
            " 98% 794M/813M [00:08<00:00, 103MB/s]\n",
            "100% 813M/813M [00:08<00:00, 105MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ut4FeJ3GrDU",
        "outputId": "2c22c3f0-cd0e-461c-a762-b3dcbc9272b8"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "filename = \"apple-leaf-disease.zip\"\n",
        "\n",
        "with ZipFile(filename,'r') as zip_dir:\n",
        "    zip_dir.extractall()\n",
        "    print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9csusyFgOQZp"
      },
      "source": [
        "##<h2>2. Custom Dataset<h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUDcPIetPKDm"
      },
      "source": [
        "class MyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self,csv_file,root_dir,transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        img_path = os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "#         print(img_path)\n",
        "#         image = io.imread(img_path)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        ylabel = torch.tensor(int(self.annotations.iloc[index,-1]))\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return (image,ylabel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcrRZsjkpsHX"
      },
      "source": [
        "## <h2>3. Initialization </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stNo_6oMpsHX",
        "outputId": "9b0bd85c-2a4e-4789-d20d-cb05217ef105"
      },
      "source": [
        "args = {}\n",
        "\n",
        "args[\"dataset\"] = \"apple\"\n",
        "args[\"model\"] = \"resnet18\"\n",
        "args[\"num_classes\"] =  4\n",
        "args[\"batch_size\"] = 16\n",
        "args[\"epochs\"] = 50\n",
        "args[\"learning_rate\"] = 0.001\n",
        "args[\"data_augmentation\"] = False\n",
        "args[\"cutout\"] = True\n",
        "args[\"n_holes\"] = 1\n",
        "args[\"length\"] = 20\n",
        "args[\"no_cuda\"] = False\n",
        "args[\"seed\"] = 0\n",
        "\n",
        "args[\"cuda\"] = not args[\"no_cuda\"] and torch.cuda.is_available()\n",
        "cudnn.benchmark = True  \n",
        "\n",
        "torch.manual_seed(args[\"seed\"])\n",
        "if args[\"cuda\"]:\n",
        "    torch.cuda.manual_seed(args[\"seed\"])\n",
        "\n",
        "test_id = args[\"dataset\"] + '_' + args[\"model\"]\n",
        "\n",
        "print(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dataset': 'apple', 'model': 'resnet18', 'num_classes': 4, 'batch_size': 16, 'epochs': 50, 'learning_rate': 0.001, 'data_augmentation': False, 'cutout': True, 'n_holes': 1, 'length': 20, 'no_cuda': False, 'seed': 0, 'cuda': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4_qyOmCpsHY"
      },
      "source": [
        "## <h2>4. DataLoader and Transforms<h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5FGdKR8psHY"
      },
      "source": [
        "### <h3>4.1 Cutout Regularization</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZvLlQc2psHY"
      },
      "source": [
        "class Cutout(object):\n",
        "    \"\"\"Randomly mask out one or more patches from an image.\n",
        "\n",
        "    Args:\n",
        "        n_holes (int): Number of patches to cut out of each image.\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "        \n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "\n",
        "        for n in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "        \n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qMpRCUEpsHY"
      },
      "source": [
        "### <h3>4.2 Transform for Train Dataset</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpAqaBEDpsHZ"
      },
      "source": [
        "def get_train_transform(cutout_length):\n",
        "  normalize_train = transforms.Normalize(mean = [0.4066, 0.5148, 0.3226],\n",
        "                                      std=[0.2011, 0.1875, 0.1882])\n",
        "\n",
        "  train_transform = transforms.Compose([])\n",
        "\n",
        "  if args[\"data_augmentation\"]:\n",
        "      train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "\n",
        "  train_transform.transforms.append(transforms.Resize((224,224)))\n",
        "  train_transform.transforms.append(transforms.ToTensor())\n",
        "  train_transform.transforms.append(normalize_train)\n",
        "\n",
        "\n",
        "  if args[\"cutout\"]:\n",
        "      train_transform.transforms.append(Cutout(n_holes=args[\"n_holes\"], length=cutout_length))\n",
        "\n",
        "  return train_transform\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV1elEW-Za0l"
      },
      "source": [
        "train_trans = get_train_transform(args[\"length\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iYn6AvIpsHZ"
      },
      "source": [
        "### <h3>4.3 Transform for Test Dataset</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi68VKd1psHZ"
      },
      "source": [
        "def get_test_transform():\n",
        "  normalize_test = transforms.Normalize(mean = [0.4047, 0.5141, 0.3240],\n",
        "                                     std=[0.2019, 0.1883, 0.1881])\n",
        "\n",
        "  test_transform = transforms.Compose([])\n",
        "  test_transform.transforms.append(transforms.Resize((224,224)))\n",
        "  test_transform.transforms.append(transforms.ToTensor())\n",
        "  test_transform.transforms.append(normalize_test)\n",
        "\n",
        "  return test_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ndjDM-gZWL1"
      },
      "source": [
        "valid_trans = get_test_transform()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMgkaLV2psHa"
      },
      "source": [
        "### <h3>4.4 Create Data Loader</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KPxZxNtpsHa"
      },
      "source": [
        "train_set = MyDataset(csv_file=\"Apple_Leaf_Disease/train_data.csv\",root_dir=\"Apple_Leaf_Disease/images/\",transform=train_trans)\n",
        "valid_set = MyDataset(csv_file=\"Apple_Leaf_Disease/test_data.csv\",root_dir=\"Apple_Leaf_Disease/images/\",transform=valid_trans)\n",
        "        \n",
        "train_loader = DataLoader(train_set, batch_size=args[\"batch_size\"],shuffle=True)\n",
        "test_loader = DataLoader(valid_set, batch_size=args[\"batch_size\"], shuffle=False)\n",
        "\n",
        "dataset_sizes = {\n",
        "    'train': len(train_loader.dataset), \n",
        "    'valid': len(test_loader.dataset)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFsHdY6wpsHa"
      },
      "source": [
        "## <h2>5. MODELS</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0e9TmM4psHa"
      },
      "source": [
        "### <h3>5.1 Test Resnet working</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8bX_haqpsHa",
        "outputId": "d6bb90ae-ca28-45cd-9754-b4ad3a1d9e40"
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "mobilenet_v2_model = models.mobilenet_v2(pretrained=True)\n",
        "inputs, labels = next(iter(test_loader))\n",
        "if use_gpu:\n",
        "    mobilenet_v2_model = mobilenet_v2_model.cuda()\n",
        "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())   \n",
        "else:\n",
        "    inputs, labels = Variable(inputs), Variable(labels)\n",
        "outputs = mobilenet_v2_model(inputs)\n",
        "outputs.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjzifAVMpsHb"
      },
      "source": [
        "### <h3>5.2 Create Model</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dFePgtMpsHb",
        "outputId": "35c482a6-083a-4433-d88c-f0864eb58fc5"
      },
      "source": [
        "cnn = models.mobilenet_v2(pretrained=True)\n",
        "args[\"num_classes\"] = 4\n",
        "# freeze all model parameters\n",
        "for param in cnn.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# New final layer with 4 classes\n",
        "num_ftrs = cnn.classifier[1].in_features\n",
        "cnn.classifier = torch.nn.Linear(num_ftrs, args[\"num_classes\"])\n",
        "\n",
        "if use_gpu:\n",
        "    cnn = cnn.cuda()\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "bs = 64\n",
        "test_dl = DataLoader(valid_set, batch_size=bs,shuffle=False)\n",
        "\n",
        "print(\"Done - Configure Model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done - Configure Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAJcAx0F9stq"
      },
      "source": [
        "## <h2>6. Unfreeze</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7nXCf5y9xIm",
        "outputId": "efae76cd-4c89-47ce-fd06-f743770624d8"
      },
      "source": [
        "for name, child in cnn.named_children():\n",
        "    if name in ['features', 'classifier']:\n",
        "        print(name + ' is unfrozen')\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        print(name + ' is frozen')\n",
        "        for param in child.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features is unfrozen\n",
            "classifier is unfrozen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-0jcN8dNDNR"
      },
      "source": [
        "## 7.Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97qwY7urNDNR"
      },
      "source": [
        "loss_func = nn.CrossEntropyLoss().cuda()\n",
        "# cnn_optimizer = torch.optim.SGD(cnn.parameters(), lr=args[\"learning_rate\"],\n",
        "#                                 momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
        "\n",
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddPBqu2VNDNR"
      },
      "source": [
        "def get_model_accuracy():\n",
        "    tot_acc = 0\n",
        "    avg_acc = 0\n",
        "  \n",
        "    # Set model to evaluation mode\n",
        "    cnn.eval()\n",
        "\n",
        "    for xbt, ybt in test_dl:\n",
        "\n",
        "        pred = cnn(xbt.to(device))\n",
        "        tot_acc += accuracy(pred,ybt.to(device))\n",
        "\n",
        "    avg_acc = tot_acc / len(test_dl)\n",
        "  \n",
        "    return avg_acc.item()\n",
        "\n",
        "\n",
        "# Print accuracy of model\n",
        "# print(\"The average accuracy is: \" + str(get_model_accuracy()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvhCP1w8NDNS"
      },
      "source": [
        "def obj_func(cutout_len):\n",
        "      \n",
        "      # lr, bs, epochs,\n",
        "      # We need to round off bs and epochs because Gaussian processes cannot deal with discrete variables \n",
        "      # cutout_len\n",
        "    bs = int(36)\n",
        "    epochs = int(18)\n",
        "\n",
        "    train_trans = get_train_transform(int(cutout_len))\n",
        "\n",
        "    train_set = MyDataset(csv_file=\"imag_data/train_data.csv\",root_dir=\"imag_data/images\",transform=train_trans)\n",
        "    valid_set = MyDataset(csv_file=\"imag_data/test_data.csv\",root_dir=\"imag_data/images\",transform=valid_trans)\n",
        "\n",
        "    train_dl = DataLoader(train_set, batch_size=bs,shuffle=True)\n",
        "    test_dl = DataLoader(valid_set, batch_size=bs, shuffle=False)\n",
        "      \n",
        "    optim = Adam(cnn.parameters(), lr = 0.0001)\n",
        "      \n",
        "    for epoch in range(epochs):\n",
        "    \n",
        "        for xb, yb in train_dl:\n",
        "        \n",
        "            # .to(device) moves torch.Tensor objects to the GPU for faster training\n",
        "        \n",
        "            preds = cnn(xb.to(device))\n",
        "            loss = loss_func(preds, yb.to(device))\n",
        "            acc = accuracy(preds,yb.to(device))\n",
        "        \n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "        \n",
        "        print(\"Train Loss: \" + str(loss.item()) + \"\\t \\t Train Accuracy: \" + str(100 * acc.item()))\n",
        "\n",
        "    acc = get_model_accuracy()\n",
        "      \n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20ukla3-NDNT",
        "outputId": "a9e136c8-5d07-4eac-860c-c1a1417d8629"
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "# 'cutout_len':(16,18) \n",
        "# Bounded region of parameter space\n",
        "pbounds = {'lr': (1e-4,1e-2), 'bs': (16,64), 'epochs': (1,30)}\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=obj_func,\n",
        "    pbounds=pbounds,\n",
        "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "optimizer.maximize(init_points=2, n_iter=3)\n",
        "\n",
        "print(optimizer.max)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | cutout... |\n",
            "-------------------------------------\n",
            "Train Loss: 0.2704342305660248\t \t Train Accuracy: 93.1034505367279\n",
            "Train Loss: 0.2779194712638855\t \t Train Accuracy: 86.20689511299133\n",
            "Train Loss: 0.11967669427394867\t \t Train Accuracy: 93.1034505367279\n",
            "Train Loss: 0.027716679498553276\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.01673622988164425\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.004650220740586519\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.03777804598212242\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.005007901228964329\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.09169457852840424\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.027327848598361015\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0006421500584110618\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.09783957898616791\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.014129611663520336\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.048511140048503876\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.0031522237695753574\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.004845279734581709\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.010169703513383865\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0009224642999470234\t \t Train Accuracy: 100.0\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.941   \u001b[0m | \u001b[0m 18.5    \u001b[0m |\n",
            "Train Loss: 0.05344273895025253\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.00010819110320881009\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.007035593036562204\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00013886917440686375\t \t Train Accuracy: 100.0\n",
            "Train Loss: 9.497736755292863e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0006647955742664635\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.033471621572971344\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.12687568366527557\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.011328449472784996\t \t Train Accuracy: 100.0\n",
            "Train Loss: 8.446491847280413e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00531509704887867\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0044355145655572414\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.000396358227590099\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00016417655569966882\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00011749887198675424\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00030123296892270446\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.004350534174591303\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0015120203606784344\t \t Train Accuracy: 100.0\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.9505  \u001b[0m | \u001b[95m 20.32   \u001b[0m |\n",
            "Train Loss: 2.6000994694186375e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.03074481338262558\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 7.592788460897282e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00917571596801281\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.007414627820253372\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.027101842686533928\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.0017364183440804482\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0001197287201648578\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00032337463926523924\t \t Train Accuracy: 100.0\n",
            "Train Loss: 5.3915784519631416e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0015801193658262491\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00014231308887246996\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.16656555235385895\t \t Train Accuracy: 93.1034505367279\n",
            "Train Loss: 0.018867429345846176\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.055172864347696304\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.06056857854127884\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 1.4387312319286139e-07\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.06616713106632233\t \t Train Accuracy: 96.55172228813171\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9453  \u001b[0m | \u001b[0m 22.0    \u001b[0m |\n",
            "Train Loss: 0.00046031971578486264\t \t Train Accuracy: 100.0\n",
            "Train Loss: 1.1254117453063373e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0002499191905371845\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0006513185799121857\t \t Train Accuracy: 100.0\n",
            "Train Loss: 5.010650966141839e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0005493819480761886\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0010503069497644901\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00010182373807765543\t \t Train Accuracy: 100.0\n",
            "Train Loss: 2.9103252927598078e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00022052372514735907\t \t Train Accuracy: 100.0\n",
            "Train Loss: 2.964775740110781e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 2.1046439542260487e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 1.5538247453150689e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0007049791747704148\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00012948636140208691\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.002397047122940421\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.4244149923324585\t \t Train Accuracy: 79.31034564971924\n",
            "Train Loss: 0.0006281748064793646\t \t Train Accuracy: 100.0\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 20.51   \u001b[0m |\n",
            "Train Loss: 0.10490377247333527\t \t Train Accuracy: 96.55172228813171\n",
            "Train Loss: 0.00022983386588748544\t \t Train Accuracy: 100.0\n",
            "Train Loss: 1.4616732187278103e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00086882064351812\t \t Train Accuracy: 100.0\n",
            "Train Loss: 5.2039717957086395e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 4.131069545110222e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 1.268789310415741e-05\t \t Train Accuracy: 100.0\n",
            "Train Loss: 1.6072505104602897e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 1.105763317355013e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.020160779356956482\t \t Train Accuracy: 100.0\n",
            "Train Loss: 5.1175129556213506e-06\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0008502137497998774\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0001291893859161064\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0003909662482328713\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0004402724443934858\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.00016741747094783932\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.018718916922807693\t \t Train Accuracy: 100.0\n",
            "Train Loss: 0.0956224575638771\t \t Train Accuracy: 96.55172228813171\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9332  \u001b[0m | \u001b[0m 16.0    \u001b[0m |\n",
            "=====================================\n",
            "{'target': 0.9505208134651184, 'params': {'cutout_len': 20.321946960652948}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6d_vFwaNDNT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}